{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Connectionist Temporal Classifier - Lasagne\n",
    "**Description**: A script to test lasagne-rnn-ctc using toy ascii alphabet data from [rakeshvar's repo](https://github.com/rakeshvar/rnn_ctc). \n",
    "**Dependencies**: print_utils.py, data.pkl *(ascii scribe) from rakeshvar*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import time\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import lasagne.layers as L\n",
    "import ctc_cost\n",
    "\n",
    "from lasagne.layers import InputLayer, LSTMLayer, ReshapeLayer, DenseLayer, NonlinearityLayer, GRULayer, GaussianNoiseLayer\n",
    "from print_utils import slab_print, prediction_printer\n",
    "\n",
    "floatX = theano.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Params \n",
    "LEARNING_RATE = 0.001\n",
    "N_BATCH = 20\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# Number of units in the hidden (recurrent) layer\n",
    "L1_UNITS = 50\n",
    "L2_UNITS = 100\n",
    "\n",
    "#### Load Ascii Toy Data File from rakeshvar ####\n",
    "filename = 'data.pkl'\n",
    "with open(filename,\"rb\") as pkl_file:\n",
    "\tdata = pkl.load(pkl_file)\n",
    "    \n",
    "chars = data['chars']\n",
    "nClasses = len(chars)\n",
    "nDims = len(data['x'][0])\n",
    "nSamples = len(data['x'])\n",
    "nTrainSamples = int(nSamples * .75)\n",
    "labels_print, labels_len = prediction_printer(chars)  \n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for x, y in zip(data['x'], data['y']):\n",
    "# Insert blanks at alternate locations in the labelling (blank is nClasses)\n",
    "   y1 = [nClasses]\n",
    "   for char in y:\n",
    "       y1 += [char, nClasses]\n",
    "\n",
    "   data_y.append(np.asarray(y1, dtype=np.int32))\n",
    "   data_x.append(np.asarray(x,  dtype=theano.config.floatX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists *data_x* and *data_y* are the training sequences and their corresponding labels. A sample sequence and label is printed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing sample input ...\n",
      " 0¦                         ¦\n",
      " 1¦               █         ¦\n",
      " 2¦               █         ¦\n",
      " 3¦    █    █     █         ¦\n",
      " 4¦     █  █      █         ¦\n",
      " 5¦      ██       █         ¦\n",
      " 6¦    ██  ██     █         ¦\n",
      " 7¦               █         ¦\n",
      " 8¦                         ¦\n",
      " 9¦                         ¦\n",
      "(array([95, 88, 95, 92, 95], dtype=int32), ' x | ')\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing sample input ...\")\n",
    "idx = 0 \n",
    "slab_print(data_x[idx])\n",
    "chars.append(' ') \n",
    "print(data_y[idx], \"\".join(chars[i] for i in data_y[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Padding  Training Data to fixed Length\n",
    "Here, both input sequences and target labels are zero-padded to fixed maximum sequence lengths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert list of input sequences to zero-padded 3D array\n",
    "num_feat   = data_x[0].shape[0]\n",
    "max_x_len  = np.max([bb.shape[1] for bb in data_x])  #list comprehension to get all lengths\n",
    "x          = np.zeros([len(data_x), max_x_len, num_feat])\n",
    "for i, examples in enumerate(data_x):\n",
    "    for j, feat in enumerate(examples):\n",
    "        for k, seq in enumerate(feat):\n",
    "            x[i][k][j]=seq\n",
    "\n",
    "            \n",
    "# Convert list of target sequences to zero-padded 2D array\n",
    "max_y_len = max(map(len,data_y))\n",
    "y=np.zeros([len(data_y), max_y_len],dtype=np.int32)\n",
    "for i, examples in enumerate(data_y):\n",
    "    for j, seq in enumerate(examples):\n",
    "        y[i][j]=seq            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Network Architecture\n",
    "And then to define the LSTM-RNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Junior/anaconda/lib/python2.7/site-packages/theano/scan_module/scan.py:1019: Warning: In the strict mode, all neccessary shared variables must be passed as a part of non_sequences\n",
      "  'must be passed as a part of non_sequences', Warning)\n"
     ]
    }
   ],
   "source": [
    "num_batch     = None  # use none to enable variable batch size\n",
    "input_seq_len = None  # use none to enable variable sequence length\n",
    "num_feat      = num_feat\n",
    "num_classes   = nClasses + 1\n",
    "\n",
    "soft = lasagne.nonlinearities.softmax\n",
    "tanh = lasagne.nonlinearities.tanh\n",
    "identity = lasagne.nonlinearities.identity\n",
    "\n",
    "l_in = InputLayer(shape=(num_batch, input_seq_len, num_feat))\n",
    "batchsize, seqlen, _ = l_in.input_var.shape\n",
    "\n",
    "l_noise = GaussianNoiseLayer(l_in, sigma=0.6) \n",
    "# l_mask  = InputLayer(shape=(batchsize, seqlen))\n",
    "# l_rnn_1 = LSTMLayer(l_noise, num_units=L1_UNITS, mask_input=l_mask)\n",
    "l_rnn_1 = LSTMLayer(l_noise, num_units=L1_UNITS)\n",
    "l_rnn_2 = LSTMLayer(l_rnn_1, num_units=L2_UNITS)\n",
    "l_shp   = ReshapeLayer(l_rnn_2,(-1, L2_UNITS))\n",
    "l_out   = DenseLayer(l_shp, num_units=num_classes, nonlinearity=identity)\n",
    "l_out_shp  = ReshapeLayer(l_out, (batchsize, seqlen, num_classes)) \n",
    "\n",
    "l_out_softmax = NonlinearityLayer(l_out, nonlinearity=soft)\n",
    "l_out_softmax_shp = ReshapeLayer(l_out_softmax,(batchsize, seqlen, num_classes))\n",
    "\n",
    "output_lin_ctc = L.get_output(l_out_shp)\n",
    "network_output = L.get_output(l_out_softmax_shp)\n",
    "all_params = L.get_all_params(l_rnn_2, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costs, Gradients & Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing updates ...\n",
      "Compiling functions ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Junior/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:135: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "# Cost functions\n",
    "target_values = T.imatrix('target_output')\n",
    "input_values  = T.imatrix()\n",
    "\n",
    "### Gradients ###\n",
    "# pseudo costs - ctc cross entropy b/n targets and linear output - used in training\n",
    "pseudo_cost = ctc_cost.pseudo_cost(target_values, output_lin_ctc)\n",
    "pseudo_cost_grad = T.grad(pseudo_cost.sum() / batchsize, all_params)\n",
    "pseudo_cost = pseudo_cost.mean()\n",
    "\n",
    "# true costs\n",
    "cost = ctc_cost.cost(target_values, network_output)\n",
    "cost = cost.mean()\n",
    "\n",
    "# Compute SGD updates for training\n",
    "print(\"Computing updates ...\")\n",
    "updates = lasagne.updates.rmsprop(pseudo_cost_grad, all_params, LEARNING_RATE)\n",
    "\n",
    "# Theano functions for training and computing cost\n",
    "print(\"Compiling functions ...\")\n",
    "train = theano.function(\n",
    "    [l_in.input_var, target_values], [cost, pseudo_cost, network_output], updates=updates)\n",
    "validate = theano.function([l_in.input_var, target_values], [cost, network_output]) \n",
    "predict  = theano.function([l_in.input_var], network_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network ...\n",
      "Batch 0/50, loss:143.98, ploss:-0.022\n",
      "Batch 1/50, loss:143.21, ploss:-0.796\n",
      "Batch 2/50, loss:142.00, ploss:-2.082\n",
      "Batch 3/50, loss:140.95, ploss:-3.232\n",
      "Batch 4/50, loss:138.54, ploss:-5.657\n",
      "Batch 5/50, loss:133.14, ploss:-11.38\n",
      "Batch 6/50, loss:115.49, ploss:-29.26\n",
      "Batch 7/50, loss:86.369, ploss:-54.46\n",
      "Batch 8/50, loss:64.904, ploss:-60.02\n",
      "Batch 9/50, loss:49.446, ploss:-48.14\n",
      "Batch 10/50, loss:43.707, ploss:-34.34\n",
      "Batch 11/50, loss:36.948, ploss:-24.17\n",
      "Batch 12/50, loss:34.621, ploss:-19.48\n",
      "Batch 13/50, loss:33.799, ploss:-17.15\n",
      "Batch 14/50, loss:32.544, ploss:-15.40\n",
      "Batch 15/50, loss:33.901, ploss:-13.39\n",
      "Batch 16/50, loss:29.552, ploss:-15.50\n",
      "Batch 17/50, loss:26.301, ploss:-16.19\n",
      "Batch 18/50, loss:24.131, ploss:-21.04\n",
      "Batch 19/50, loss:22.438, ploss:-18.18\n",
      "Batch 20/50, loss:22.036, ploss:-20.31\n",
      "Batch 21/50, loss:23.491, ploss:-12.35\n",
      "Batch 22/50, loss:21.709, ploss:-17.10\n",
      "Batch 23/50, loss:22.664, ploss:-12.40\n",
      "Batch 24/50, loss:19.545, ploss:-15.31\n",
      "Batch 25/50, loss:20.217, ploss:-10.66\n",
      "Batch 26/50, loss:17.779, ploss:-13.70\n",
      "Batch 27/50, loss:18.705, ploss:-10.49\n",
      "Batch 28/50, loss:16.192, ploss:-6.794\n",
      "Batch 29/50, loss:17.277, ploss:-10.63\n",
      "Batch 30/50, loss:15.554, ploss:-11.19\n",
      "Batch 31/50, loss:15.005, ploss:-9.875\n",
      "Batch 32/50, loss:16.339, ploss:-10.91\n",
      "Batch 33/50, loss:15.883, ploss:-8.694\n",
      "Batch 34/50, loss:14.446, ploss:-8.072\n",
      "Batch 35/50, loss:16.530, ploss:-8.072\n",
      "Batch 36/50, loss:14.492, ploss:-8.072\n",
      "Batch 37/50, loss:16.398, ploss:-8.072\n",
      "Batch 38/50, loss:15.616, ploss:-8.072\n",
      "Batch 39/50, loss:14.194, ploss:-8.072\n",
      "Batch 40/50, loss:15.486, ploss:-8.072\n",
      "Batch 41/50, loss:14.506, ploss:-8.072\n",
      "Batch 42/50, loss:16.005, ploss:-8.072\n",
      "Batch 43/50, loss:15.206, ploss:-8.072\n",
      "Batch 44/50, loss:15.481, ploss:-8.072\n",
      "Batch 45/50, loss:14.501, ploss:-8.072\n",
      "Batch 46/50, loss:15.196, ploss:-8.072\n",
      "Batch 47/50, loss:16.582, ploss:-8.072\n",
      "Batch 48/50, loss:15.284, ploss:-8.072\n",
      "Batch 49/50, loss:14.095, ploss:-8.072\n"
     ]
    }
   ],
   "source": [
    "#### Training Network ####\n",
    "print(\"Training network ...\")\n",
    "num_batches_train = int(np.ceil(len(x) / N_BATCH))\n",
    "split_ratio = 0.7*num_batches_train\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\tnow = time.time\n",
    "\ttlosses = []\n",
    "\tvlosses = []\n",
    "\tplosses = []\n",
    "\tprobabilities = []\n",
    "\n",
    "\ttraindata = zip(x,y)\n",
    "\tnp.random.shuffle(traindata)\n",
    "\tsequences, labels = zip(*traindata)\n",
    "\n",
    "\n",
    "\tfor batch in range(num_batches_train):\n",
    "\t\tbatch_slice = slice(N_BATCH * batch, N_BATCH * (batch + 1))\n",
    "\t\txi = sequences[batch_slice]\n",
    "\t\tyi = labels[batch_slice]\n",
    "\t\tif batch < split_ratio:\n",
    "\t\t\tloss, ploss, probs = train(xi,yi)\n",
    "\t\t\ttlosses.append(loss)\n",
    "\t\t\tplosses.append(ploss)\n",
    "\t\telse:\n",
    "\t\t\tloss, probs = validate(xi,yi)\n",
    "\t\t\ty_pred = np.argmax(probs, axis=-1)                           \n",
    "\t\t\tvlosses.append(loss)\n",
    "\t\t\tprobabilities.append(probs)\n",
    "\n",
    "\t\tprint(\"Batch {0}/{1}, loss:{2:.6}, ploss:{3:.6}\".format(batch,num_batches_train,loss,ploss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0¦     ███                             ¦\n",
      " 1¦    █   █      ░                     ¦\n",
      " 2¦        █                            ¦\n",
      " 3¦      ██                             ¦\n",
      " 4¦               ██ █                  ¦\n",
      " 5¦      █       █  ██                  ¦\n",
      " 6¦              █   █                  ¦\n",
      " 7¦               ██ █                  ¦\n",
      " 8¦                  █                  ¦\n",
      " 9¦               ███                   ¦\n",
      "(array([95, 31, 95, 71, 95,  0,  0], dtype=int32), ' ? g   ')\n"
     ]
    }
   ],
   "source": [
    "# Print a test example\n",
    "idx=2\n",
    "slab_print(xi[idx].T)\n",
    "print(yi[idx], \"\".join(chars[i] for i in yi[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
      "       95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
      "       95,  0,  0]), '                                     ')\n"
     ]
    }
   ],
   "source": [
    "# Predict a test example \n",
    "probs=predict(xi)\n",
    "y_pred=np.argmax(probs,axis=-1)\n",
    "print(y_pred[idx], \"\".join(chars[i] for i in y_pred[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
