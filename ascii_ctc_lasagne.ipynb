{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Connectionist Temporal Classifier - Lasagne\n",
    "**Description**: A script to test lasagne-rnn-ctc using toy ascii alphabet data from [rakeshvar's repo](https://github.com/rakeshvar/rnn_ctc). \n",
    "**Dependencies**: print_utils.py, data.pkl *(ascii scribe) from rakeshvar*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import time\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import lasagne.layers as L\n",
    "import ctc_cost\n",
    "\n",
    "from lasagne.layers import InputLayer, LSTMLayer, ReshapeLayer, DenseLayer, NonlinearityLayer, GRULayer, GaussianNoiseLayer\n",
    "from print_utils import slab_print, prediction_printer\n",
    "\n",
    "floatX = theano.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Params \n",
    "LEARNING_RATE = 0.001\n",
    "N_BATCH = 100\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# Number of units in the hidden (recurrent) layer\n",
    "L1_UNITS = 50\n",
    "L2_UNITS = 100\n",
    "\n",
    "#### Load Ascii Toy Data File from rakeshvar ####\n",
    "filename = 'data.pkl'\n",
    "with open(filename,\"rb\") as pkl_file:\n",
    "\tdata = pkl.load(pkl_file)\n",
    "    \n",
    "chars = data['chars']\n",
    "nClasses = len(chars)\n",
    "nDims = len(data['x'][0])\n",
    "nSamples = len(data['x'])\n",
    "nTrainSamples = int(nSamples * .75)\n",
    "labels_print, labels_len = prediction_printer(chars)  \n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for x, y in zip(data['x'], data['y']):\n",
    "# Insert blanks at alternate locations in the labelling (blank is nClasses)\n",
    "   y1 = [nClasses]\n",
    "   for char in y:\n",
    "       y1 += [char, nClasses]\n",
    "\n",
    "   data_y.append(np.asarray(y1, dtype=np.int32))\n",
    "   data_x.append(np.asarray(x,  dtype=theano.config.floatX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists *data_x* and *data_y* are the training sequences and their corresponding labels. A sample sequence and label is printed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing sample input ...\n",
      " 0¦                          ¦\n",
      " 1¦                          ¦\n",
      " 2¦                          ¦\n",
      " 3¦          █ ███           ¦\n",
      " 4¦          ██  █           ¦\n",
      " 5¦          █   █           ¦\n",
      " 6¦          █  ░█           ¦\n",
      " 7¦                          ¦\n",
      " 8¦                          ¦\n",
      " 9¦                          ¦\n",
      "(array([95, 78, 95], dtype=int32), ' n ')\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing sample input ...\")\n",
    "idx = 0 \n",
    "slab_print(data_x[idx])\n",
    "chars.append(' ') \n",
    "print(data_y[idx], \"\".join(chars[i] for i in data_y[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Padding  Training Data to fixed Length\n",
    "Here, both input sequences and target labels are zero-padded to fixed maximum sequence lengths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert list of input sequences to zero-padded 3D array\n",
    "num_feat   = data_x[0].shape[0]\n",
    "max_x_len  = np.max([bb.shape[1] for bb in data_x])  #list comprehension to get all lengths\n",
    "x          = np.zeros([len(data_x), max_x_len, num_feat])\n",
    "for i, examples in enumerate(data_x):\n",
    "    for j, feat in enumerate(examples):\n",
    "        for k, seq in enumerate(feat):\n",
    "            x[i][k][j]=seq\n",
    "\n",
    "            \n",
    "# Convert list of target sequences to zero-padded 2D array\n",
    "max_y_len = max(map(len,data_y))\n",
    "y=np.zeros([len(data_y), max_y_len],dtype=np.int32)\n",
    "for i, examples in enumerate(data_y):\n",
    "    for j, seq in enumerate(examples):\n",
    "        y[i][j]=seq            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Network Architecture\n",
    "And then to define the LSTM-RNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_batch     = None  # use none to enable variable batch size\n",
    "input_seq_len = None  # use none to enable variable sequence length\n",
    "num_feat      = num_feat\n",
    "num_classes   = nClasses + 1\n",
    "\n",
    "soft = lasagne.nonlinearities.softmax\n",
    "tanh = lasagne.nonlinearities.tanh\n",
    "identity = lasagne.nonlinearities.identity\n",
    "\n",
    "l_in = InputLayer(shape=(num_batch, input_seq_len, num_feat))\n",
    "batchsize, seqlen, _ = l_in.input_var.shape\n",
    "\n",
    "l_noise = GaussianNoiseLayer(l_in, sigma=0.6) \n",
    "# l_mask  = InputLayer(shape=(batchsize, seqlen))\n",
    "# l_rnn_1 = LSTMLayer(l_noise, num_units=L1_UNITS, mask_input=l_mask)\n",
    "l_rnn_1 = LSTMLayer(l_noise, num_units=L1_UNITS)\n",
    "l_rnn_2 = LSTMLayer(l_rnn_1, num_units=L2_UNITS)\n",
    "l_shp   = ReshapeLayer(l_rnn_2,(-1, L2_UNITS))\n",
    "l_out   = DenseLayer(l_shp, num_units=num_classes, nonlinearity=identity)\n",
    "l_out_shp  = ReshapeLayer(l_out, (batchsize, seqlen, num_classes)) \n",
    "\n",
    "l_out_softmax = NonlinearityLayer(l_out, nonlinearity=soft)\n",
    "l_out_softmax_shp = ReshapeLayer(l_out_softmax,(batchsize, seqlen, num_classes))\n",
    "\n",
    "output_lin_ctc = L.get_output(l_out_shp)\n",
    "network_output = L.get_output(l_out_softmax_shp)\n",
    "all_params = L.get_all_params(l_rnn_2, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costs, Gradients & Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing updates ...\n",
      "Compiling functions ...\n"
     ]
    }
   ],
   "source": [
    "# Cost functions\n",
    "target_values = T.imatrix('target_output')\n",
    "input_values  = T.imatrix()\n",
    "\n",
    "### Gradients ###\n",
    "# pseudo costs - ctc cross entropy b/n targets and linear output - used in training\n",
    "pseudo_cost = ctc_cost.pseudo_cost(target_values, output_lin_ctc)\n",
    "pseudo_cost_grad = T.grad(pseudo_cost.sum() / batchsize, all_params)\n",
    "pseudo_cost = pseudo_cost.mean()\n",
    "\n",
    "# true costs\n",
    "cost = ctc_cost.cost(target_values, network_output)\n",
    "cost = cost.mean()\n",
    "\n",
    "# Compute SGD updates for training\n",
    "print(\"Computing updates ...\")\n",
    "updates = lasagne.updates.rmsprop(pseudo_cost_grad, all_params, LEARNING_RATE)\n",
    "\n",
    "# Theano functions for training and computing cost\n",
    "print(\"Compiling functions ...\")\n",
    "train = theano.function(\n",
    "    [l_in.input_var, target_values], [cost, pseudo_cost, network_output], updates=updates)\n",
    "validate = theano.function([l_in.input_var, target_values], [cost, network_output]) \n",
    "predict  = theano.function([l_in.input_var], network_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network ...\n",
      "Batch 0/500, loss:105.67, ploss:0.0850\n",
      "Batch 1/500, loss:105.24, ploss:-0.464\n",
      "Batch 2/500, loss:104.65, ploss:-0.961\n",
      "Batch 3/500, loss:104.23, ploss:-1.488\n",
      "Batch 4/500, loss:103.19, ploss:-2.625\n",
      "Batch 5/500, loss:101.81, ploss:-4.000\n",
      "Batch 6/500, loss:98.678, ploss:-6.771\n",
      "Batch 7/500, loss:92.498, ploss:-13.64\n",
      "Batch 8/500, loss:78.640, ploss:-26.03\n",
      "Batch 9/500, loss:59.029, ploss:-39.87\n",
      "Batch 10/500, loss:47.284, ploss:-39.50\n",
      "Batch 11/500, loss:40.361, ploss:-31.55\n",
      "Batch 12/500, loss:34.249, ploss:-24.85\n",
      "Batch 13/500, loss:31.153, ploss:-20.65\n",
      "Batch 14/500, loss:30.786, ploss:-17.31\n",
      "Batch 15/500, loss:27.003, ploss:-15.67\n",
      "Batch 16/500, loss:27.872, ploss:-13.82"
     ]
    }
   ],
   "source": [
    "#### Training Network ####\n",
    "print(\"Training network ...\")\n",
    "num_batches_train = int(np.ceil(len(x) / N_BATCH))\n",
    "split_ratio = 0.8*num_batches_train\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\tnow = time.time\n",
    "\ttlosses = []\n",
    "\tvlosses = []\n",
    "\tplosses = []\n",
    "\tprobabilities = []\n",
    "\n",
    "\ttraindata = zip(x,y)\n",
    "\tnp.random.shuffle(traindata)\n",
    "\tsequences, labels = zip(*traindata)\n",
    "\n",
    "\n",
    "\tfor batch in range(num_batches_train):\n",
    "\t\tbatch_slice = slice(N_BATCH * batch, N_BATCH * (batch + 1))\n",
    "\t\txi = sequences[batch_slice]\n",
    "\t\tyi = labels[batch_slice]\n",
    "\t\tif batch < split_ratio:\n",
    "\t\t\tloss, ploss, probs = train(xi,yi)\n",
    "\t\t\ttlosses.append(loss)\n",
    "\t\t\tplosses.append(ploss)\n",
    "\t\telse:\n",
    "\t\t\tloss, probs = validate(xi,yi)\n",
    "\t\t\ty_pred = np.argmax(probs, axis=-1)                           \n",
    "\t\t\tvlosses.append(loss)\n",
    "\t\t\tprobabilities.append(probs)\n",
    "\n",
    "\t\tprint(\"Batch {0}/{1}, loss:{2:.6}, ploss:{3:.6}\".format(batch,num_batches_train,loss,ploss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print a test example\n",
    "idx=4\n",
    "slab_print(xi[idx].T)\n",
    "print(yi[idx], \"\".join(chars[i] for i in yi[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95,\n",
      "       95, 95, 95, 95, 95, 95, 95, 95, 95, 95]), '                           ')\n"
     ]
    }
   ],
   "source": [
    "# Predict a test example \n",
    "probs=predict(xi)\n",
    "y_pred=np.argmax(probs,axis=-1)\n",
    "print(y_pred[idx], \"\".join(chars[i] for i in y_pred[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Type                          Data/Info\n",
      "------------------------------------------------------------\n",
      "DenseLayer           type                          <class 'lasagne.layers.dense.DenseLayer'>\n",
      "GRULayer             type                          <class 'lasagne.layers.recurrent.GRULayer'>\n",
      "GaussianNoiseLayer   type                          <class 'lasagne.layers.noise.GaussianNoiseLayer'>\n",
      "InputLayer           type                          <class 'lasagne.layers.input.InputLayer'>\n",
      "L                    module                        <module 'lasagne.layers' <...>gne/layers/__init__.pyc'>\n",
      "L1_UNITS             int                           50\n",
      "L2_UNITS             int                           100\n",
      "LEARNING_RATE        float                         0.001\n",
      "LSTMLayer            type                          <class 'lasagne.layers.recurrent.LSTMLayer'>\n",
      "NUM_EPOCHS           int                           1\n",
      "N_BATCH              int                           100\n",
      "NonlinearityLayer    type                          <class 'lasagne.layers.sp<...>ecial.NonlinearityLayer'>\n",
      "ReshapeLayer         type                          <class 'lasagne.layers.shape.ReshapeLayer'>\n",
      "T                    module                        <module 'theano.tensor' f<...>ano/tensor/__init__.pyc'>\n",
      "all_params           list                          n=30\n",
      "batch                int                           499\n",
      "batch_slice          slice                         slice(49900, 50000, None)\n",
      "batchsize            TensorVariable                Subtensor{int64}.0\n",
      "bb                   ndarray                       10x25: 250 elems, type `float64`, 2000 bytes\n",
      "char                 int                           87\n",
      "chars                list                          n=96\n",
      "cost                 TensorVariable                Elemwise{true_div,no_inplace}.0\n",
      "ctc_cost             module                        <module 'ctc_cost' from 'ctc_cost.py'>\n",
      "data                 dict                          n=3\n",
      "data_x               list                          n=50000\n",
      "data_y               list                          n=50000\n",
      "epoch                int                           0\n",
      "examples             ndarray                       5: 5 elems, type `int32`, 20 bytes\n",
      "feat                 ndarray                       25: 25 elems, type `float64`, 200 bytes\n",
      "filename             str                           data.pkl\n",
      "floatX               str                           float64\n",
      "i                    int                           49999\n",
      "identity             function                      <function linear at 0x106a1db18>\n",
      "idx                  int                           4\n",
      "input_seq_len        NoneType                      None\n",
      "input_values         TensorVariable                <TensorType(int32, matrix)>\n",
      "j                    int                           4\n",
      "k                    int                           24\n",
      "l_in                 InputLayer                    <lasagne.layers.input.Inp<...>er object at 0x1187be950>\n",
      "l_noise              GaussianNoiseLayer            <lasagne.layers.noise.Gau<...>er object at 0x10b352a90>\n",
      "l_out                DenseLayer                    <lasagne.layers.dense.Den<...>er object at 0x1079a4f90>\n",
      "l_out_shp            ReshapeLayer                  <lasagne.layers.shape.Res<...>er object at 0x1079a4f10>\n",
      "l_out_softmax        NonlinearityLayer             <lasagne.layers.special.N<...>er object at 0x110b09b10>\n",
      "l_out_softmax_shp    ReshapeLayer                  <lasagne.layers.shape.Res<...>er object at 0x110b2e190>\n",
      "l_rnn_1              LSTMLayer                     <lasagne.layers.recurrent<...>er object at 0x1079a4f50>\n",
      "l_rnn_2              LSTMLayer                     <lasagne.layers.recurrent<...>er object at 0x1079a4fd0>\n",
      "l_shp                ReshapeLayer                  <lasagne.layers.shape.Res<...>er object at 0x110b267d0>\n",
      "labels               tuple                         n=50000\n",
      "labels_len           function                      <function ylen at 0x113f1c050>\n",
      "labels_print         function                      <function yprint at 0x106b8ce60>\n",
      "lasagne              module                        <module 'lasagne' from '/<...>es/lasagne/__init__.pyc'>\n",
      "loss                 ndarray                       : 1 elems, type `float64`, 8 bytes\n",
      "max_x_len            int64                         27\n",
      "max_y_len            int                           5\n",
      "nClasses             int                           95\n",
      "nDims                int                           10\n",
      "nSamples             int                           50000\n",
      "nTrainSamples        int                           37500\n",
      "network_output       TensorVariable                Reshape{3}.0\n",
      "now                  builtin_function_or_method    <built-in function time>\n",
      "np                   module                        <module 'numpy' from '/Us<...>ages/numpy/__init__.pyc'>\n",
      "num_batch            NoneType                      None\n",
      "num_batches_train    int                           500\n",
      "num_classes          int                           96\n",
      "num_feat             int                           10\n",
      "output_lin_ctc       TensorVariable                Reshape{3}.0\n",
      "pkl                  module                        <module 'pickle' from '/U<...>ib/python2.7/pickle.pyc'>\n",
      "pkl_file             file                          <closed file 'data.pkl', <...>mode 'rb' at 0x106b59ed0>\n",
      "ploss                ndarray                       : 1 elems, type `float64`, 8 bytes\n",
      "plosses              list                          n=400\n",
      "predict              Function                      <theano.compile.function_<...>on object at 0x133e5bb10>\n",
      "prediction_printer   function                      <function prediction_printer at 0x106b8cde8>\n",
      "probabilities        list                          n=100\n",
      "probs                ndarray                       100x27x96: 259200 elems, type `float64`, 2073600 bytes (1 Mb)\n",
      "pseudo_cost          TensorVariable                Elemwise{true_div,no_inplace}.0\n",
      "pseudo_cost_grad     list                          n=30\n",
      "seq                  int32                         95\n",
      "seqlen               TensorVariable                Subtensor{int64}.0\n",
      "sequences            tuple                         n=50000\n",
      "slab_print           function                      <function slab_print at 0x106b8cd70>\n",
      "soft                 function                      <function softmax at 0x106a1d9b0>\n",
      "split_ratio          float                         400.0\n",
      "tanh                 function                      <function tanh at 0x106a1da28>\n",
      "target_values        TensorVariable                target_output\n",
      "theano               module                        <module 'theano' from '/U<...>ges/theano/__init__.pyc'>\n",
      "time                 module                        <module 'time' from '/Use<...>2.7/lib-dynload/time.so'>\n",
      "tlosses              list                          n=400\n",
      "train                Function                      <theano.compile.function_<...>on object at 0x133705590>\n",
      "traindata            list                          n=50000\n",
      "updates              OrderedDict                   OrderedDict([(<TensorType<...>wise{sub,no_inplace}.0)])\n",
      "validate             Function                      <theano.compile.function_<...>on object at 0x1373cbcd0>\n",
      "vlosses              list                          n=100\n",
      "x                    ndarray                       50000x27x10: 13500000 elems, type `float64`, 108000000 bytes (102 Mb)\n",
      "xi                   tuple                         n=100\n",
      "y                    ndarray                       50000x5: 250000 elems, type `int32`, 1000000 bytes (976 kb)\n",
      "y1                   list                          n=5\n",
      "y_pred               ndarray                       100x27: 2700 elems, type `int64`, 21600 bytes\n",
      "yi                   tuple                         n=100\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
